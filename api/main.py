"""
FastAPI backend for CoSpa - Location discovery chat API
Integrates with OpenAI GPT-4o (latest), Qdrant vector search, and PostgreSQL
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
from dotenv import load_dotenv
from openai import OpenAI
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
import psycopg

# Load environment variables
load_dotenv()

# Initialize FastAPI app
app = FastAPI(
    title="CoSpa API",
    description="Location discovery chat API with semantic search",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify exact origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize clients
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
qdrant_client = QdrantClient(
    url=os.getenv("QDRANT_API_URL"),
    api_key=os.getenv("QDRANT_API_KEY"),
)
embedding_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Database config
DB_CONFIG = {
    'host': os.getenv('POSTGRES_HOST'),
    'user': os.getenv('POSTGRES_USER'),
    'password': os.getenv('POSTGRES_PASSWORD'),
    'database': os.getenv('POSTGRES_DB'),
    'port': int(os.getenv('POSTGRES_PORT'))
}

COLLECTION_NAME = "cospa_sites"

# Pydantic models
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    message: str
    history: Optional[List[ChatMessage]] = []
    user_location: Optional[dict] = None

class LocationResult(BaseModel):
    id: str
    name: str
    type: str
    brand: Optional[str]
    rating: Optional[float]
    review_count: Optional[int]
    address: str
    distance: Optional[str]
    lat: Optional[float]
    lng: Optional[float]
    phone_number: Optional[str]
    link_google: Optional[str]
    link_web: Optional[str]
    thumbnail_url: Optional[str]
    amenities: List[str] = []
    isSponsored: bool = False
    description: Optional[str]

class ChatResponse(BaseModel):
    reply: str
    locations: List[LocationResult]

# Helper functions
def calculate_distance(lat1: float, lng1: float, lat2: float, lng2: float) -> float:
    """Calculate distance between two coordinates using Haversine formula (in km)"""
    from math import radians, sin, cos, sqrt, atan2
    
    R = 6371  # Earth radius in kilometers
    
    lat1_rad = radians(lat1)
    lat2_rad = radians(lat2)
    delta_lat = radians(lat2 - lat1)
    delta_lng = radians(lng2 - lng1)
    
    a = sin(delta_lat / 2) ** 2 + cos(lat1_rad) * cos(lat2_rad) * sin(delta_lng / 2) ** 2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    
    return R * c

def search_locations(query: str, limit: int = 5, user_location: Optional[dict] = None) -> List[dict]:
    """Search locations using Qdrant vector search with optional location filtering"""
    try:
        # Generate embedding for query
        query_embedding = embedding_model.encode([query])[0]
        
        # Search in Qdrant with more results initially to filter by location
        search_limit = limit * 5 if user_location else limit * 2
        search_results = qdrant_client.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_embedding.tolist(),
            limit=search_limit
        )
        
        locations = []
        for result in search_results:
            payload = result.payload
            
            # Skip if missing coordinates
            if not payload.get('lat') or not payload.get('lng'):
                continue
                
            location_data = {
                'id': payload.get('id'),
                'name': payload.get('name'),
                'type': payload.get('type'),
                'brand': payload.get('brand'),
                'rating': payload.get('rating'),
                'review_count': payload.get('review_count'),
                'address': payload.get('address'),
                'city': payload.get('city'),
                'lat': payload.get('lat'),
                'lng': payload.get('lng'),
                'phone_number': payload.get('phone_number'),
                'link_google': payload.get('link_google'),
                'link_web': payload.get('link_web'),
                'thumbnail_url': payload.get('thumbnail_url'),
                'place_id': payload.get('place_id'),
                'score': result.score,
                'distance_from_user': None
            }
            
            # Filter by user location if provided
            if user_location and user_location.get('lat') and user_location.get('lng'):
                distance = calculate_distance(
                    user_location['lat'], user_location['lng'],
                    location_data['lat'], location_data['lng']
                )
                location_data['distance_from_user'] = distance
                
                # Only include locations within 30km radius
                if distance <= 30:
                    locations.append(location_data)
            else:
                locations.append(location_data)
        
        # Additional validation: ensure locations are not too far apart
        if len(locations) > 1:
            # Use first location as reference (highest semantic match)
            reference = locations[0]
            filtered_locations = [reference]
            
            for loc in locations[1:]:
                distance_from_ref = calculate_distance(
                    reference['lat'], reference['lng'],
                    loc['lat'], loc['lng']
                )
                
                # Only include if within 20km of the first result
                # This prevents mixing different cities
                if distance_from_ref <= 20:
                    filtered_locations.append(loc)
                    
                if len(filtered_locations) >= limit:
                    break
            
            return filtered_locations
        
        # Return top results after filtering
        return locations[:limit]
    except Exception as e:
        print(f"Error searching locations: {e}")
        return []

def create_system_prompt(locations: List[dict], user_location: Optional[dict] = None) -> str:
    """Create system prompt with location context and user location"""
    
    base_prompt = """B·∫°n l√† CoSpa - tr·ª£ l√Ω ·∫£o chuy√™n nghi·ªáp trong lƒ©nh v·ª±c F&B (Food & Beverage) v√† b·∫•t ƒë·ªông s·∫£n vƒÉn ph√≤ng t·∫°i Vi·ªát Nam.

üéØ NHI·ªÜM V·ª§ CH√çNH:
H·ªó tr·ª£ freelancer, h·ªçc sinh, sinh vi√™n t√¨m ki·∫øm kh√¥ng gian l√†m vi·ªác v√† h·ªçc t·∫≠p ph√π h·ª£p v·ªõi nhu c·∫ßu c√° nh√¢n.

üë§ ƒê·ªêI T∆Ø·ª¢NG PH·ª§C V·ª§:
- Freelancer c·∫ßn kh√¥ng gian l√†m vi·ªác linh ho·∫°t
- H·ªçc sinh, sinh vi√™n c·∫ßn ch·ªó h·ªçc t·∫≠p y√™n tƒ©nh
- Ng∆∞·ªùi l√†m vi·ªác remote c·∫ßn m√¥i tr∆∞·ªùng chuy√™n nghi·ªáp
- Nh√≥m nh·ªè c·∫ßn kh√¥ng gian h·ªçp/l√†m vi·ªác nh√≥m

üí° CHUY√äN M√îN C·ª¶A B·∫†N:
1. **F&B Knowledge:**
   - Cafe, qu√°n c√† ph√™ ph√π h·ª£p l√†m vi·ªác/h·ªçc t·∫≠p
   - Coworking space v·ªõi ƒë·∫ßy ƒë·ªß ti·ªán nghi
   - ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng wifi, ·ªï c·∫Øm ƒëi·ªán, ƒë·ªô ·ªìn
   - Gi√° c·∫£ ph√π h·ª£p v·ªõi sinh vi√™n/freelancer

2. **B·∫•t ƒë·ªông s·∫£n vƒÉn ph√≤ng:**
   - Kh√¥ng gian l√†m vi·ªác chung (coworking)
   - VƒÉn ph√≤ng chia s·∫ª, ph√≤ng h·ªçp
   - V·ªã tr√≠ thu·∫≠n ti·ªán, giao th√¥ng
   - Chi ph√≠ h·ª£p l√Ω theo t·ª´ng khu v·ª±c

3. **T∆∞ v·∫•n c√° nh√¢n h√≥a:**
   - Ph√¢n t√≠ch nhu c·∫ßu c·ª• th·ªÉ c·ªßa ng∆∞·ªùi d√πng
   - ƒê·ªÅ xu·∫•t ƒë·ªãa ƒëi·ªÉm ph√π h·ª£p v·ªõi budget
   - So s√°nh ∆∞u/nh∆∞·ª£c ƒëi·ªÉm c√°c l·ª±a ch·ªçn
   - G·ª£i √Ω th·ªùi gian t·ªët nh·∫•t ƒë·ªÉ ƒë·∫øn

üìã C√ÅCH TR·∫¢ L·ªúI:
- Th√¢n thi·ªán, g·∫ßn g≈©i nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n t∆∞ v·∫•n
- Tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ ng∆∞·ªùi d√πng s·ª≠ d·ª•ng (Ti·∫øng Vi·ªát ho·∫∑c English)
- Cung c·∫•p th√¥ng tin chi ti·∫øt: rating, gi√°, wifi, ƒë·ªô ·ªìn, ·ªï c·∫Øm
- ƒê·ªÅ xu·∫•t 2-3 l·ª±a ch·ªçn t·ªët nh·∫•t v·ªõi l√Ω do r√µ r√†ng
- Kh√¥ng d√πng markdown formatting trong c√¢u tr·∫£ l·ªùi
- Lu√¥n h·ªèi th√™m n·∫øu c·∫ßn l√†m r√µ nhu c·∫ßu

üéØ TI√äU CH√ç ∆ØU TI√äN KHI T∆Ø V·∫§N:
1. Wifi m·∫°nh, ·ªïn ƒë·ªãnh (quan tr·ªçng nh·∫•t cho freelancer)
2. ·ªî c·∫Øm ƒëi·ªán ƒë·∫ßy ƒë·ªß
3. Kh√¥ng gian y√™n tƒ©nh (cho h·ªçc t·∫≠p)
4. Gi√° c·∫£ ph·∫£i chƒÉng (ph√π h·ª£p sinh vi√™n)
5. V·ªã tr√≠ thu·∫≠n ti·ªán, d·ªÖ t√¨m
6. Gi·ªù m·ªü c·ª≠a linh ho·∫°t
7. ƒê·ªì u·ªëng/th·ª©c ƒÉn ch·∫•t l∆∞·ª£ng, gi√° h·ª£p l√Ω

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- **B·∫ÆT BU·ªòC h·ªèi r√µ ƒë·ªãa ch·ªâ** n·∫øu ng∆∞·ªùi d√πng ch∆∞a n√≥i c·ª• th·ªÉ:
  + Ph∆∞·ªùng/X√£ n√†o?
  + Qu·∫≠n/Huy·ªán n√†o?
  + T·ªânh/Th√†nh ph·ªë n√†o?
  V√≠ d·ª•: "B·∫°n mu·ªën t√¨m ·ªü ph∆∞·ªùng n√†o, qu·∫≠n n√†o ·ªü H√† N·ªôi?"
  
- Lu√¥n h·ªèi v·ªÅ budget v√† khu v·ª±c ∆∞u ti√™n
- Ph√¢n bi·ªát nhu c·∫ßu l√†m vi·ªác c√° nh√¢n vs nh√≥m
- G·ª£i √Ω th·ªùi gian √≠t ƒë√¥ng ƒë·ªÉ c√≥ ch·ªó ng·ªìi t·ªët
- C·∫£nh b√°o n·∫øu ƒë·ªãa ƒëi·ªÉm th∆∞·ªùng ƒë√¥ng v√†o gi·ªù cao ƒëi·ªÉm
- ƒê·ªÅ xu·∫•t ƒë·ªãa ƒëi·ªÉm v·ªõi to·∫° ƒë·ªô (lat, lng) ƒë·ªÉ ng∆∞·ªùi d√πng d·ªÖ t√¨m tr√™n b·∫£n ƒë·ªì

üìç V·ªÄ V·ªä TR√ç:
- N·∫øu ng∆∞·ªùi d√πng ch·ªâ n√≥i "H√† N·ªôi" ho·∫∑c "S√†i G√≤n" ‚Üí H·ªèi th√™m qu·∫≠n/ph∆∞·ªùng c·ª• th·ªÉ
- N·∫øu ng∆∞·ªùi d√πng n√≥i "g·∫ßn ƒë√¢y" ‚Üí H·ªèi v·ªã tr√≠ hi·ªán t·∫°i ho·∫∑c khu v·ª±c h·ªç th∆∞·ªùng ·ªü
- Lu√¥n ƒë·ªÅ c·∫≠p ƒë·∫øn ƒë·ªãa ch·ªâ chi ti·∫øt (ph∆∞·ªùng, qu·∫≠n) khi gi·ªõi thi·ªáu ƒë·ªãa ƒëi·ªÉm
- CH·ªà gi·ªõi thi·ªáu ƒë·ªãa ƒëi·ªÉm trong c√πng th√†nh ph·ªë v·ªõi ng∆∞·ªùi d√πng (kh√¥ng ƒë∆∞·ª£c l·∫´n H√† N·ªôi v√† TP.HCM)
"""
    
    # Add user location context if available
    if user_location and user_location.get('lat') and user_location.get('lng'):
        base_prompt += f"\n\nüìç V·ªä TR√ç NG∆Ø·ªúI D√ôNG:\nTo·∫° ƒë·ªô hi·ªán t·∫°i: {user_location['lat']}, {user_location['lng']}\n"
    
    if locations:
        base_prompt += "\n\nüìç C√ÅC ƒê·ªäA ƒêI·ªÇM LI√äN QUAN:\n"
        for i, loc in enumerate(locations, 1):
            rating_str = f"{loc['rating']}/5" if loc['rating'] else "N/A"
            base_prompt += f"{i}. {loc['name']} ({loc['type']}) - Rating: {rating_str}\n"
            base_prompt += f"   ƒê·ªãa ch·ªâ: {loc['address']}\n"
            if loc.get('lat') and loc.get('lng'):
                base_prompt += f"   To·∫° ƒë·ªô: {loc['lat']}, {loc['lng']}\n"
            if loc.get('brand'):
                base_prompt += f"   Th∆∞∆°ng hi·ªáu: {loc['brand']}\n"
            if loc.get('phone_number'):
                base_prompt += f"   SƒêT: {loc['phone_number']}\n"
    
    return base_prompt

# API Routes
@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "ok",
        "service": "CoSpa API",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    """Detailed health check"""
    return {
        "status": "healthy",
        "openai": "connected" if os.getenv("OPENAI_API_KEY") else "not configured",
        "qdrant": "connected" if os.getenv("QDRANT_API_KEY") else "not configured",
        "postgres": "configured" if all(DB_CONFIG.values()) else "not configured"
    }

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Chat endpoint with location search
    Uses OpenAI GPT-4o (latest version) for intelligent conversation
    """
    try:
        # Search for relevant locations with user location filter
        locations = search_locations(request.message, limit=5, user_location=request.user_location)
        
        # Create system prompt with location context and user location
        system_prompt = create_system_prompt(locations, user_location=request.user_location)
        
        # Prepare messages for OpenAI
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # Add conversation history
        for msg in request.history:
            messages.append({
                "role": msg.role,
                "content": msg.content
            })
        
        # Add current user message
        messages.append({
            "role": "user",
            "content": request.message
        })
        
        # Call OpenAI API with latest GPT-4o model
        response = openai_client.chat.completions.create(
            model="gpt-4o",  # Latest GPT-4o model (automatically uses newest version)
            messages=messages,
            temperature=0.7,
            max_tokens=800  # Increased for more detailed responses
        )
        
        reply = response.choices[0].message.content
        
        # Format locations for response
        location_results = []
        for loc in locations:
            # Generate mock amenities based on type
            amenities = []
            if loc['type'] in ['Cafe', 'cafe']:
                amenities = ['wifi', 'coffee', 'seating']
            elif loc['type'] in ['Coworking', 'coworking space']:
                amenities = ['wifi', 'meeting rooms', 'quiet space']
            
            # Calculate distance (mock for now)
            distance = f"{round(loc.get('score', 0) * 10, 1)} km"
            
            location_results.append(LocationResult(
                id=loc['id'],
                name=loc['name'],
                type=loc['type'],
                brand=loc.get('brand'),
                rating=loc.get('rating'),
                review_count=loc.get('review_count'),
                address=loc['address'],
                distance=distance,
                lat=loc.get('lat'),
                lng=loc.get('lng'),
                phone_number=loc.get('phone_number'),
                link_google=loc.get('link_google'),
                link_web=loc.get('link_web'),
                thumbnail_url=loc.get('thumbnail_url') or f"https://picsum.photos/400/300?random={hash(loc['id']) % 1000}",
                amenities=amenities,
                isSponsored=False,  # Can be enhanced with actual sponsored data
                description=f"Great {loc['type'].lower()} in {loc['address'].split(',')[-1].strip() if ',' in loc['address'] else 'Vietnam'}"
            ))
        
        return ChatResponse(
            reply=reply,
            locations=location_results
        )
        
    except Exception as e:
        print(f"Error in chat endpoint: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/locations/search")
async def search_locations_endpoint(q: str, limit: int = 10):
    """Direct location search endpoint"""
    try:
        locations = search_locations(q, limit=limit)
        return {"results": locations, "count": len(locations)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats")
async def get_stats():
    """Get database statistics"""
    try:
        # Get Qdrant stats
        collection_info = qdrant_client.get_collection(collection_name=COLLECTION_NAME)
        
        # Get PostgreSQL stats
        conn = psycopg.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM sites WHERE is_active = TRUE")
        total_sites = cursor.fetchone()[0]
        
        cursor.execute("SELECT city, COUNT(*) FROM sites WHERE is_active = TRUE GROUP BY city ORDER BY COUNT(*) DESC LIMIT 5")
        top_cities = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        return {
            "total_sites": total_sites,
            "vector_db_points": collection_info.points_count,
            "top_cities": [{"city": city, "count": count} for city, count in top_cities]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
